<!DOCTYPE html>
<html lang="en-us">
    
  <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.46" />

    

<title></title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Yingyan Xu"/>

<meta property="og:title" content="" />
<meta property="og:description" content="Yingyan Xu" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://yingyan-xu.github.io/" />



<meta property="og:updated_time" content="2018-08-13T23:52:44&#43;08:00"/>

<meta property="og:site_name" content="Yingyan Xu" />










    

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">



<link rel="stylesheet" href="/css/hyde-hyde.css">
<link rel="stylesheet" href="/css/print.min.css" media="print">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    
    

<link href="https://yingyan-xu.github.io/index.xml" rel="alternate" type="application/rss+xml" title="" />
<link href="https://yingyan-xu.github.io/index.xml" rel="feed" type="application/rss+xml" title="" />


</head>


    <body class="theme-base-08 ">
        
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://yingyan-xu.github.io/"></a>
      </span>
      
      
      
      <div class="author-image">
        <img src="https://yingyan-xu.github.io/img/HEAD.jpg" alt="Author Image" class="img--circle img--headshot element--center"> 
      </div>
      
      <p class="site__description">
         Yingyan Xu 
      </p>
    </div>
    <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="#about">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#education">
						<span>Education</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#internship">
						<span>Internship</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#projects">
						<span>Projects</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#coursework">
						<span>Coursework</span>
					</a>
				</li>
			 
		
		</li>
	</ul>
</div>

    <p>
      <section class="social">
	
	
	
	
	
	
	
	
	
	
	
	
	&nbsp;<a href="mailto:yingyanxu.0102@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

    </p>
    
  </div>
  <div>
  </div>
</div>

        <div class="content container">
            
  <div class="post-list">
    
    
      <div class="post-list__item">
        <span class="item__title--big">
          <a name="about">ABOUT</a>
        </span>
        
        <p>I am a third year undergraduate student in Department of Automation, <a href="http://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, expecting to graduate in June 2019.</p>

<p>My research interests include video analysis, robotic vision and general problems in computer vision. My current work focuses on dense detailed multi-label action detection tasks in untrimmed videos.</p>

<hr />

        
        </div>
        
      <div class="post-list__item">
        <span class="item__title--big">
          <a name="education">EDUCATION</a>
        </span>
        
        

<h4 id="shanghai-jiao-tong-university">SHANGHAI JIAO TONG UNIVERSITY</h4>

<ul>
<li>Major in Automation, School of Electronic Information and Electrical Engineering</li>
<li>Average Score: 90.4 / 100</li>
<li>Rank: 3 / 91<br /></li>
</ul>

<hr />

        
        </div>
        
      <div class="post-list__item">
        <span class="item__title--big">
          <a name="internship">INTERNSHIP</a>
        </span>
        
        

<h4 id="hikvision-research-institute">HIKVISION RESEARCH INSTITUTE</h4>

<p><strong>Research Intern, Intelligent Algorithm Department</strong></p>

<p>Over the last few years, while excellent results have been achieved in the field of static image understanding, there is still a long way to go for video understanding. I’m interested in this challenging topic and particularly interested in human activity detection tasks. I have done some related research work, listed as follows:</p>

<ul>
<li><p>Examined large-scale video datasets which depict a variety of complex human activities in untrimmed videos, including <strong>Charades</strong>, <strong>THUMOS</strong> and <strong>MultiTHUMOS</strong>. Chose MultiTHUMOS dataset for close scrutiny, considering the granularity of action categories, the density of annotations and the scale of the dataset (too large training sets require high performance equipment and may not be practical for research purposes).</p></li>

<li><p>Learned the basic ideas of existing approaches on MultiTHUMOS, including <strong>MultiLSTM</strong>, <strong>predictive-corrective networks</strong>, <strong>biLSTM</strong>, <strong>siLSTM</strong> and <strong>super-event</strong> presentation. Briefly compared their strengths and weaknesses. Summarized their respective innovations and contributions.</p></li>

<li><p>Focused on modeling temporal relationships between activities. Thoroughly studied the algorithm details of <strong>sub-event</strong>, <strong>super-event</strong> and the latest <strong>TGM</strong> (Temporal Gaussian Mixture) approach, which obtained the best known performance. Carried out experiments after code implementation and gained results similar to the authors’ (<strong>33.4 mAP</strong> for I3D+super-event and <strong>?? mAP</strong> for I3D+super-event+TGM).</p></li>
</ul>

<p>Future works may include:</p>

<ul>
<li><p>Visualization works to explicitly demonstrate what the learned sub-events and super-events are.</p></li>

<li><p>Analyzing correct and incorrect detection examples to gain insights and further improve the algorithms.</p></li>

<li><p>Combination of multiple existing approaches to generate new ideas.</p></li>
</ul>

<hr />

        
        
        
        </div>
        
      <div class="post-list__item">
        <span class="item__title--big">
          <a name="projects">PROJECTS</a>
        </span>
        
        

<h4 id="obstacle-detection-for-vision-based-navigation">Obstacle Detection for Vision Based Navigation</h4>

<p><font color="gray">Autonomous Robot Lab, SJTU</font></p>

<p>Detecting the obstacles accurately and reliably is important for navigating the robot or autonomous vehicle. The latest sensor technologies and computer vision plays a key role in making this pragmatically realizable. Deep Neural Networks like Convolutional Neural Network (CNN) are widely used for object detection and segmentation algorithms.</p>

<ul>
<li><p>Used the SegNet encoder-decoder architecture for pixel-wise semantic segmentation of the video frame. The network was trained and tested using CamVid dataset, achieving a test accuracy of 68.4%?</p></li>

<li><p>For road region contour detection step, the simple chain approximation method helped reduce the redundancy by saving only the essential points of the contour instead of storing every single point that constitutes the contour.</p></li>

<li><p>Used the convex hull instead of just using the contour in order to avoid missing out any obstacles that might appear very closer or partially over the road region.</p></li>

<li><p>Plotted minimum fitting bounding rectangles over the vehicle and pedestrian regions using bounding box algorithm.</p></li>

<li><p>Used the point polygon test to determine whether an obstacle (pedestrians or other vehicles) is inside the ROI, i.e., within the convex hull of the road region.</p></li>
</ul>

<p>Future work can include integrating this methodology to the autonomous platform available in the campus, e.g., the logistic robot in our lab.</p>

<h4 id="object-counting">Object Counting</h4>

<p><font color="gray">Digital Image Processing Course</font></p>

<hr />

        
        
        
        </div>
        
      <div class="post-list__item">
        <span class="item__title--big">
          <a name="coursework">COURSEWORK</a>
        </span>
        
        

<h4 id="upcoming-courses">UPCOMING COURSES</h4>

<table>
   <tr>
      <td>AU419</td>
      <td>Computer Networking</td>
      <td>Fall 2018</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU422</td>
      <td>Operation Systems</td>
      <td>Fall 2018</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>CS400</td>
      <td>Database</td>
      <td>Fall 2018</td>
      <td>SJTU</td>
   </tr>
</table>

<h4 id="completed-courses">COMPLETED COURSES</h4>

<table>
   <tr>
      <td>CS430</td>
      <td>Data Structure</td>
      <td>100</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>CS048</td>
      <td>C++ Programing</td>
      <td>98</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>CS331</td>
      <td>Computer Control Technology </td>
      <td>100</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU416</td>
      <td>Robotics</td>
      <td>97</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU310</td>
      <td>Motion Control Systems</td>
      <td>95</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU326</td>
      <td>Digital Image Processing</td>
      <td>90</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU311</td>
      <td>Pattern Recognition</td>
      <td>90</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>EI304</td>
      <td>Principles of Automatic Control</td>
      <td>92</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>MA119</td>
      <td>Probability and Statistics</td>
      <td>90</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>MA043</td>
      <td>Mathematical Analysis</td>
      <td>93</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>MA115</td>
      <td>Discrete Mathematics</td>
      <td>88</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>MA077</td>
      <td>Linear Algebra</td>
      <td>87</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU302</td>
      <td>Modern Control Theory</td>
      <td>98</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>AU308</td>
      <td>Digital Signal Processing</td>
      <td>97</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>EE213</td>
      <td>Embedded Systems</td>
      <td>98</td>
      <td>SJTU</td>
   </tr>
   <tr>
      <td>PH002</td>
      <td>Physics</td>
      <td>97</td>
      <td>SJTU</td>
   </tr>
</table>

<h4 id="online-courses">ONLINE COURSES</h4>

<table>
   <tr>
      <td>Deep Learning</td>
      <td>Summer 2018</td>
      <td>Coursera</td>
   </tr>
</table>

        
        </div>
        
     
  </div>

        </div>
        

<script defer src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"
  integrity="sha384-4oV5EgaV02iISL2ban6c/RmotsABqE4yZxZLcYMAdG7FAPsyHYAPpywE9PJo+Khy"
  crossorigin="anonymous">
</script>


    </body>
</html>
