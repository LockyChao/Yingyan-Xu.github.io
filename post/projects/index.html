<!DOCTYPE html>
<html lang="en-us">
    
    

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.46" />

    
    
    

<title>PROJECTS • </title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="PROJECTS"/>
<meta name="twitter:description" content="Obstacle Detection for Vision Based Navigation for Autonomous Driving Autonomous Robot Lab, SJTU
  Detecting the obstacles accurately and reliably is important for navigating the robot or autonomous vehicle. The cost effective monocular camera sensor along with computer vision techniques plays a key role in making this pragmatically realizable. Deep Neural Networks like Convolutional Neural Network (CNN) are widely used for object detection and segmentation algorithms.
 Used the SegNet encoder-decoder architecture for pixel-wise semantic segmentation of the video frame."/>

<meta property="og:title" content="PROJECTS" />
<meta property="og:description" content="Obstacle Detection for Vision Based Navigation for Autonomous Driving Autonomous Robot Lab, SJTU
  Detecting the obstacles accurately and reliably is important for navigating the robot or autonomous vehicle. The cost effective monocular camera sensor along with computer vision techniques plays a key role in making this pragmatically realizable. Deep Neural Networks like Convolutional Neural Network (CNN) are widely used for object detection and segmentation algorithms.
 Used the SegNet encoder-decoder architecture for pixel-wise semantic segmentation of the video frame." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yingyan-xu.github.io/post/projects/" />



<meta property="article:published_time" content="2018-08-11T00:24:06&#43;08:00"/>

<meta property="article:modified_time" content="2018-08-11T00:24:06&#43;08:00"/>

<meta property="og:site_name" content="Yingyan Xu" />











    

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">



<link rel="stylesheet" href="/css/hyde-hyde.css">
<link rel="stylesheet" href="/css/print.min.css" media="print">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    
    

</head>


    <body class="theme-base-08 ">
        
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://yingyan-xu.github.io/"></a>
      </span>
      
      
      
      <div class="author-image">
        <img src="https://yingyan-xu.github.io/img/HEAD.jpg" alt="Author Image" class="img--circle img--headshot element--center"> 
      </div>
      
      <p class="site__description">
         Yingyan Xu 
      </p>
    </div>
    <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="#about">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#education">
						<span>Education</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#intership">
						<span>Internship</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#projects">
						<span>Projects</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="#coursework">
						<span>Coursework</span>
					</a>
				</li>
			 
		
		</li>
	</ul>
</div>

    <p>
      <section class="social">
	
	
	
	
	
	
	
	
	
	
	
	
	&nbsp;<a href="mailto:yingyanxu.0102@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

    </p>
    
  </div>
  <div>
  </div>
</div>

        <div class="content container">
            
    <article>
  <header>
    <h1>PROJECTS</h1>
     
    
<div class="post__meta">
    
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


  </header>
  <div class="post">
    <p><font size=5>Obstacle Detection for Vision Based Navigation for Autonomous Driving</font></br>
<a href="http://robotics.sjtu.edu.cn/index.php?r=site/index">Autonomous Robot Lab, SJTU</a></p>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/4-pSmm8NlNI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<p>Detecting the obstacles accurately and reliably is important for navigating the robot or autonomous vehicle. The cost effective monocular camera sensor along with computer vision techniques plays a key role in making this pragmatically realizable. Deep Neural Networks like Convolutional Neural Network (CNN) are widely used for object detection and segmentation algorithms.</p>

<ul>
<li><p>Used the <strong>SegNet</strong> encoder-decoder architecture for pixel-wise <strong>semantic segmentation</strong> of the video frame. The network was trained and tested using CamVid dataset, achieving a test accuracy of <strong>68.4%</strong>.</p></li>

<li><p>For road region <strong>contour detection</strong> step, the <strong>simple chain approximation</strong> method helped reduce the redundancy by saving only the essential points of the contour instead of storing every single point that constitutes the contour.</p></li>

<li><p>Used the <strong>convex hull</strong> instead of just using the contour in order to avoid missing out any obstacles that might appear very closer or partially over the road region.</p></li>

<li><p>Plotted minimum fitting bounding rectangles over the vehicle and pedestrian regions using <strong>bounding box</strong> algorithm. Used the <strong>point polygon test</strong> to determine whether an obstacle (pedestrians or other vehicles) is inside the ROI, i.e., within the convex hull of the road region.</p></li>
</ul>

<p>Future work can include integrating this methodology to the autonomous platform available in the campus, e.g., the logistic robot in our lab.
&nbsp;</p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><font size=5>Object Counting</font></br>
<font color="gray">Digital Image Processing Course</font></p>

<p><img src="https://raw.githubusercontent.com/Yingyan-Xu/Yingyan-Xu.github.io/master/dip.PNG" alt="Aaron Swartz" />
The number of objects in an image is one of the basic information and is of great use. The tedious counting process is time consuming and should be replaced by machines. I tried out counting tasks for common block objects (e.g., apples, coins) using <strong>watershed segmentation</strong> and strip objects (e.g., matches, cigarettes) based on <strong>Hough line transform</strong>, then focused on automatic segmentation and counting in cell images and implemented a method as follows:</p>

<ul>
<li><p>Applied a <strong>threshold filter</strong> and <strong>morphological transform</strong> to reduce the noise. Detected the adhere cells based on the area and shape of the cells.</p></li>

<li><p>The boundary information was used to generate the <strong>Freeman chain codes</strong>.</p></li>

<li><p>Identified the <strong>concave points</strong> based on the relationship between the difference of the chain code and the curvature. Cell segmentation and counting were completed based on the characteristics of the concave points.
&nbsp;</p></li>
</ul>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><font size=5>Smart Car Projects – Vision Based and Sensor Based</font></br>
<font color="gray">Intelligent Mobile Robot Project</font></p>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/dRoUKyuKtCY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<p>For a Raspberry Pi car robot with only camera sensors, one in the front and another in the back, implemented functions as follows:</p>

<ul>
<li>Automatic line following.</br></li>
<li>Stop according to the stop sign.</br></li>
<li>Reverse parking.</br></li>
<li>Move forward following the arrow signs.<br /></li>
</ul>

<p>For a sensor based car robot equipped with three sensor modules including infrared distance sensors, line followers and collision sensors, implemented functions as follows:</p>

<ul>
<li>Automatic line following.</br></li>
<li>Solve a maze.</br></li>
<li>Remote control with Bluetooth.</br></li>
</ul>

<hr />

  </div>
  

<div class="post--navigation post--navigation-single">
    
    <a href="/post/coursework/" class="post--navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">COURSEWORK</span>
    </a>
    
    
    <a href="/post/internship/" class="post--navigation-next">
      <span class="navigation-tittle">INTERNSHIP</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>


        </div>
        
    
<script defer src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"
  integrity="sha384-4oV5EgaV02iISL2ban6c/RmotsABqE4yZxZLcYMAdG7FAPsyHYAPpywE9PJo+Khy"
  crossorigin="anonymous">
</script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

<script type="text/javascript">
    hljs.configure({languages: []});
    hljs.initHighlightingOnLoad();
</script>



    



    </body>
</html>
